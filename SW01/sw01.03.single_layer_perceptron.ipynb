{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hslu_logo.png](img/hslu_logo.png)\n",
    "\n",
    "## Week 01\n",
    "\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "# Excercise: Single-Layer-Perceptron using PyTorch\n",
    "---\n",
    "---\n",
    "This excercise is to illustrate the single layer perceptrion through application on synthetic 2D-classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "from utils import create_data, plot_img, plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the creation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,img = create_data(1000, imgName='Regions00.png')\n",
    "\n",
    "plot_img(img)\n",
    "\n",
    "plot_data(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SingleLayerPerceptron:\n",
    "    \"\"\"\n",
    "    Single layer Perceptron class doing the forward and backward step\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input, num_output):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "\n",
    "        Arguments:\n",
    "        num_input -- number of input values\n",
    "        num_output -- number of output values (categories)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model = torch.nn.Sequential(\n",
    "            ### START YOUR CODE ###*\n",
    "            torch.nn....,\n",
    "            torch.nn...\n",
    "            ### END YOUR CODE ###*\n",
    "        )\n",
    "                         \n",
    "        self.cost_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        \n",
    "    def propagate(self, X):\n",
    "        \"\"\"\n",
    "        calculates the function estimation based on current parameters [W,B]\n",
    "        \"\"\"    \n",
    "        self.Y_pred = self.model(X)\n",
    "           \n",
    "     \n",
    "    def back_propagate(self, cost):\n",
    "        \"\"\"\n",
    "        calculates the backpropagation results based on expected output y\n",
    "        this function must be performed AFTER the corresponding propagte step\n",
    "        \"\"\"    \n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    " \n",
    "\n",
    "    def calc_cost(self, Y):\n",
    "        \"\"\"\n",
    "        calculates the MSE loss function\n",
    "        \"\"\"\n",
    "        cost = self.cost_fn(self.Y_pred, Y)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "        \n",
    "        \n",
    "    def gradient_descend(self, alpha):\n",
    "        \"\"\"\n",
    "        does the gradient descend based on results from last back_prop step with learning rate alpha\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param in self.model.parameters():\n",
    "                param -= alpha * param.grad\n",
    "            \n",
    "     \n",
    "        \n",
    "    def calc_error(self, Y):\n",
    "        \"\"\"\n",
    "        get error information\n",
    "        \"\"\"\n",
    "        m = Y.shape[0]\n",
    "\n",
    "        Y_pred_argmax = torch.argmax(self.Y_pred, dim=1)\n",
    "        train_error = torch.sum(Y != Y_pred_argmax) / m\n",
    "\n",
    "        return train_error\n",
    "\n",
    "        \n",
    "        \n",
    "    def optimize(self, data, epochs, alpha, debug=0):\n",
    "        \"\"\"\n",
    "        performs epochs number of gradient descend steps and appends result to output array\n",
    "\n",
    "        Arguments:\n",
    "        data -- dictionary with data\n",
    "        epochs -- number of epochs\n",
    "        alpha -- learning rate\n",
    "        debug -- False (default)/True; get info on each gradient descend step\n",
    "        \"\"\"\n",
    "        \n",
    "        # save results before 1st step\n",
    "        for i0 in range(0, epochs):\n",
    "            #do prediction\n",
    "            self.propagate(data['X_train'])\n",
    "            #determine the loss \n",
    "            cost = self.calc_cost(data['Y_train'])\n",
    "            #determine the error\n",
    "            self.back_propagate(cost)\n",
    "            #do the correction step\n",
    "            self.gradient_descend(alpha)\n",
    "            #calculate the error\n",
    "            error = self.calc_error(data['Y_train'])\n",
    "            \n",
    "            if debug and np.mod(i0, debug) == 0:\n",
    "                print('step %r, cost %r, error %r' % (i0, cost.item(), error.item()))\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,img = create_data(1000, imgName='Regions00.png')\n",
    "\n",
    "plot_img(img)\n",
    "\n",
    "plot_data(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion to torch tensor and normalisation \n",
    "\n",
    "Training is more robust if the data is normalised such that all features have the same scale. Two typical schemes exist:\n",
    "- min-max-rescaling:\n",
    "  Data is scaled to interval $[0,1]$\n",
    "- min-max-normalization\n",
    "  Data is scaled to interval $[-1,1]$\n",
    "\n",
    "Type conversion is also important because PyTorch is very strict on type compatibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensor\n",
    "data_X = torch.tensor(x, dtype=torch.float32)\n",
    "data_Y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "#normalize data: original data is overwritten\n",
    "data_min, data_max = torch.min(data_X), torch.max(data_X)\n",
    "print('original min-max values are: %r, %r and type %r' % (data_min.item(), data_max.item(), data_min.dtype))\n",
    "\n",
    "normalize_tpye = 1\n",
    "\n",
    "if normalize_tpye == 0:\n",
    "    #min-max-rescaling\n",
    "    data_X = (data_X - data_min) / (data_max - data_min)    \n",
    "else:\n",
    "    #min-max-normalization\n",
    "    data_X = 2*(data_X - data_min) / (data_max - data_min) - 1\n",
    "\n",
    "data_min, data_max = torch.min(data_X), torch.max(data_X)\n",
    "print('now min-max values are: %r, %r and type %r' % (data_min.item(), data_max.item(), data_min.dtype))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Perceptron and do optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'X_train' : data_X, 'Y_train' : data_Y}\n",
    "\n",
    "num_input = data_X.shape[1]\n",
    "num_output = len(torch.unique(data_Y))\n",
    "\n",
    "slp = SingleLayerPerceptron(num_input, num_output)\n",
    "\n",
    "slp.optimize(data, 200, 0.5, 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.05\n",
    "grid = np.mgrid[-1.:1.:step,-1.:1.:step]\n",
    "\n",
    "grid_points = grid.reshape(2,int(grid.size/2)).T\n",
    "\n",
    "y_pred = torch.argmax(slp.model(torch.tensor(grid_points, dtype=torch.float32)),1)\n",
    "plot_data(np.append(grid_points, data['X_train'],axis=0), np.append(y_pred, data['Y_train']))\n",
    "#plot_data(grid_points, y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
